{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65LuGjqVyO62"
   },
   "source": [
    "**Sentiment classification** is the automated process of identifying opinions in text and labeling them as positive, negative, or neutral, based on the emotions customers express within them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2dGOJ-gyO6_"
   },
   "source": [
    "**Transfer learning** is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task!\n",
    "\n",
    "**Word Embeddings** Word embeddings are a type of word representation that look at the context of words which allows words with similar meaning to have a similar vector representation.\n",
    "\n",
    "\n",
    "1. Each word is represented as  a vector.\n",
    "\n",
    "2. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network.\n",
    "\n",
    "3. They can be considered an improvement over sparse representations used in simpler bag of word model representations.\n",
    "\n",
    "FYI - A very common feature extraction procedures for sentences and documents is the bag-of-words approach (BOW). In this approach, we look at the histogram of the words within the text, i.e. considering each word count as a feature.\n",
    "\n",
    "— Page 69, Neural Network Methods in Natural Language Processing, 2017\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "Word2Vec is a shallow, two-layer neural networks which is trained to reconstruct linguistic contexts of words.\n",
    "Input: Large Corpus of words\n",
    "Output: Vector Space, with each unique word in the corpus being assigned a corresponding vector in the space.\n",
    "\n",
    "\n",
    "Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
    "\n",
    "\n",
    "**Deep Network** Deep network takes the sequence of embedding vectors as input and converts them to a compressed representation. The compressed representation effectively captures all the information in the sequence of words in the text. The deep network part is usually an RNN or some forms of it like LSTM/GRU. The dropout is added to overcome the tendency to overfit, a very common problem with RNN based networks.\n",
    "\n",
    "**Recurrent Neural Networks** Recurrent Neural Networks are used to handle sequential data. One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames/words might inform the understanding of the present frame/words. \n",
    "\n",
    "\n",
    "Sometimes, we only need to look at recent information to perform the present task. But unfortunately, as that gap grows, RNNs become unable to learn to connect the information.\n",
    "\n",
    "Standard RNNs fail to learn in the presence of time lags greater than 5 – 10 discrete time steps between relevant input events and target signals. The vanishing error problem casts doubt on whether standard RNNs can indeed exhibit significant practical advantages over time window-based feedforward networks. A recent model, “Long Short-Term Memory” (LSTM), is not affected by this problem. LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error flow through “constant error carrousels” (CECs) within special units, called cells\n",
    "\n",
    "**LSTM** Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB dataset: https://www.tensorflow.org/datasets/catalog/imdb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lmj6_HZ8yO7A",
    "outputId": "3c113dd3-0613-4b83-d2b5-afd9c1d98409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIHQbJ3CyO7C"
   },
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "BaMm1x_tyO7E",
    "outputId": "fa761dd1-a9de-41c0-fdb4-8475efc5827d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1\n",
       "4  Bill Paxton has taken the true story of the 19...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB_movie_reviews.csv\", encoding='utf-8')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9exPr1isyO7F"
   },
   "source": [
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "1. **Tokenization** is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords.\n",
    "\n",
    "2. Removing **Punctuations**\n",
    "\n",
    "3. Removing tokens which are not alphabetic\n",
    "\n",
    "4. **Stopwords Removal**: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qkeUDsxyO7G"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "reviews_lines = list()\n",
    "\n",
    "lines = df['review'].values.tolist()\n",
    "\n",
    "for line in lines:\n",
    "  tokens = word_tokenize(line)\n",
    "  tokens = [word.lower() for word in tokens]\n",
    "  table = str.maketrans('', '', string.punctuation) # remove punctuations\n",
    "\n",
    "  stripped = [w.translate(table) for w in tokens]\n",
    "  # remove non aplahabetical tokens:\n",
    "  words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "  # filter out stop words:\n",
    "  stop_words = set(stopwords.words('english')) \n",
    "  #use all stop words from nltk corpus\n",
    "  #if the word is not in stop_words consider it\n",
    "  words = [w for w in words if not w in stop_words]\n",
    "  # list of tokens\n",
    "  reviews_lines.append(words)\n",
    "  # multiple list of tokens, where each list is corresponding to a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVmxaNygyO7H"
   },
   "source": [
    "**Word2Vec** is a simple Neural Network with one hidden layer & has weights and during training, its goal is to adjust those weights to reduce the loss function.\n",
    "\n",
    "During the training, weights are adjusted through back-propagation. Once the training is completed, instead of taking the entire model, we just take the **hidden weights** which are our word embeddings.\n",
    "\n",
    "Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
    "\n",
    "Gensim is an Open Source Python Library which can be used to implement Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_lkTcjvyO7H",
    "outputId": "c7a5a4d6-7a7b-415d-ec61-5557c085cfd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: %d 134156\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "#window=5 how many words it looks to predict the next word\n",
    "#min_count =1 , means any word with less that 1 frequency will be dropped\n",
    "#gensim uses continuous bag of words , if nothing is specified\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=reviews_lines, size=EMBEDDING_DIM, \\\n",
    "                               window=5, min_count=1)\n",
    "# look ta the vocabulary size:\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "print(\"Vocabulary size: %d\",  len(words) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9gZwHw_yO7I"
   },
   "source": [
    "**Saving** the word2vec model in ASCII (word2vec) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCPY3eP2yO7I",
    "outputId": "9ad32220-2309-46e5-f2cf-92547194c125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x7f4df5f3f990>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['garbage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G74BcEtmyO7J"
   },
   "source": [
    "Lets test our Word2Vec Model to see how it performs using utility functions provided in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJYICQBCyO7J",
    "outputId": "222363b2-0f31-4288-cd37-76252ff35bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filmmaker', 0.7155443429946899),\n",
       " ('writerdirector', 0.655202329158783),\n",
       " ('altman', 0.6380494832992554),\n",
       " ('directors', 0.6370048522949219),\n",
       " ('screenwriter', 0.6078441739082336),\n",
       " ('harlin', 0.6026256084442139),\n",
       " ('directorial', 0.5954552292823792),\n",
       " ('filmmakers', 0.59075927734375),\n",
       " ('lumet', 0.5735146999359131),\n",
       " ('soderbergh', 0.5678800940513611)]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"director\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeWiiMDQyO7K",
    "outputId": "3eb01241-730f-47b6-8ee6-e4d9b357ca0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('protagonist', 0.7001582384109497),\n",
       " ('attraction', 0.6926031112670898),\n",
       " ('sexually', 0.6880298256874084),\n",
       " ('nurse', 0.6755688190460205),\n",
       " ('girl', 0.6682547330856323),\n",
       " ('passionate', 0.6615655422210693),\n",
       " ('vulnerable', 0.6604877710342407),\n",
       " ('damsel', 0.6604134440422058),\n",
       " ('seductive', 0.6579244136810303),\n",
       " ('stepmother', 0.6578255295753479)]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check potivive words (couple of words) and a negative word\n",
    "model.wv.most_similar(positive=['actress', 'heroine'], negative=['actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RXXd0SnyO7J"
   },
   "source": [
    "Let’s see the result of semantically reasonable word vectors (actress - actor + heroine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1ZrwP5vyO7K"
   },
   "source": [
    "**Odd One out** - Finding the odd word out of the given list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_uiTyBOyO7K",
    "outputId": "c356304c-e13d-4e15-c96a-a2ffe805b9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"film movie theater tea\".split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6GUmNu_yO7L"
   },
   "source": [
    "## Save model in ASCII (word2vec) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMTQ3datyO7L"
   },
   "outputs": [],
   "source": [
    "filename=\"imdb_embedding_word2vec.txt\"\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NfzM1kvyO7L"
   },
   "source": [
    "## Load the embeddings from the file into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXnJOxYryO7L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "embeddings_index = {}\n",
    "f=open('imdb_embedding_word2vec.txt', encoding='utf-8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    # first index is word folloowed by its vector\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1R_Cc1yyO7L"
   },
   "source": [
    "**Tokenization** is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords. \n",
    "\n",
    "**Padding** All the neural networks require to have inputs that have the same shape and size. However, when we pre-process and use the texts as inputs for our model e.g. LSTM, not all the sentences have the same length. In other words, naturally, some of the sentences are longer or shorter. We need to have the inputs with the same size, this is where the padding is necessary.\n",
    "\n",
    "**Splitting the data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-KlvIEHyO7M",
    "outputId": "294a91f7-bff6-46ef-9626-4a5e28bbc34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 100)\n",
      "(50000,)\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(reviews_lines)\n",
    "\n",
    "sequences = tokenizer_obj.texts_to_sequences(reviews_lines)\n",
    "\n",
    "max_length = 100 # max length of sequence, otherwise pad it\n",
    "word_index = tokenizer_obj.word_index\n",
    "\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "sentiment = df['sentiment'].values\n",
    "\n",
    "print(review_pad.shape)\n",
    "print(sentiment.shape)\n",
    "\n",
    "# shuffle the indices:\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "\n",
    "num_validation_samples = int(VALIDATION_SPLIT*review_pad.shape[0])\n",
    "\n",
    "X_val_pad = review_pad[:num_validation_samples]\n",
    "y_val = sentiment[:num_validation_samples]\n",
    "X_train_pad = review_pad[num_validation_samples:]\n",
    "y_train = sentiment[num_validation_samples:]\n",
    "\n",
    "print(X_train_pad.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfnQwiVAyO7M"
   },
   "source": [
    "## Splitting Train data further into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCHUR4Y9yO7M"
   },
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.1\n",
    "\n",
    "num_test_samples = int(TEST_SPLIT * X_train_pad.shape[0])\n",
    "X_test_pad = X_train_pad[:num_test_samples]\n",
    "y_test = y_train[:num_test_samples]\n",
    "X_train_pad = X_train_pad[num_test_samples:]\n",
    "y_train = y_train[num_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QajAPkY3yO7M",
    "outputId": "a7b862d8-cc8a-42ff-c471-95dc39f7815f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 100)\n",
      "(36000,)\n",
      "(10000, 100)\n",
      "(10000,)\n",
      "(4000, 100)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val_pad.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_test_pad.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzVpjQleyO7N"
   },
   "source": [
    "## Creating an Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i4udOI7yO7N"
   },
   "outputs": [],
   "source": [
    "# our embeddings are in the dctionary format. We have to transform them into \n",
    "# matrix format executed by Keras\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) +1\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM ))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UImlDo2jyO7N"
   },
   "source": [
    "## Training \n",
    "\n",
    "Defining the Model\n",
    "\n",
    "In Keras, A **Sequential model** is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "1. Load pre-trained word embeddings into an Embedding layer\n",
    "\n",
    "2. Adding LSTM Layer\n",
    "\n",
    "3. Adding Dense Layer\n",
    "\n",
    "**model.compile** used to Configures the model for training.\n",
    "\n",
    "\n",
    "**model.add()** function is used to add layers to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcUjdHshyO7N",
    "outputId": "fa41d51b-973a-48bd-f07d-0ca7a85f0ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "summary of the model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          13415700  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,432,757\n",
      "Trainable params: 17,057\n",
      "Non-trainable params: 13,415,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words, \n",
    "                            EMBEDDING_DIM, \n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=max_length, \n",
    "                            trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"summary of the model...\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0X-lX-bkyO7N"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "Use the .fit method.\n",
    "\n",
    "Assign the model.fit() method to a variable, which will store the Training, Validation Loss and Accuracy for each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ux7BtSmXyO7O",
    "outputId": "3d9813dc-260b-469a-d5a2-4985b234e195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 - 86s - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 2/10\n",
      "282/282 - 83s - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 3/10\n",
      "282/282 - 82s - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 4/10\n",
      "282/282 - 83s - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 5/10\n",
      "282/282 - 83s - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 6/10\n",
      "282/282 - 82s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 7/10\n",
      "282/282 - 84s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 8/10\n",
      "282/282 - 83s - loss: 0.6931 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.5021\n",
      "Epoch 9/10\n",
      "282/282 - 82s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.4979\n",
      "Epoch 10/10\n",
      "282/282 - 83s - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4979\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train, batch_size=128, epochs= 10, validation_data=(X_val_pad, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7-ThjjAyO7O"
   },
   "source": [
    "## Evaluating the Model on Test Set\n",
    "\n",
    "**Score** is the evaluation of the loss function for a given input.\n",
    "\n",
    "**Accuracy** How accurate your model's prediction is compared to the true data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aJ_mzYnZDDF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-tBqEnUyO7O",
    "outputId": "c1c6bc5e-f8c3-466d-bfb3-175138a4869d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 27ms/step - loss: 0.6931 - accuracy: 0.5045\n",
      "Test score: 0.6931068897247314\n",
      "Test accuracy: 0.5044999718666077\n"
     ]
    }
   ],
   "source": [
    "score , acc = model.evaluate(X_test_pad, y_test, batch_size = 128)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML6vB56cyO7O"
   },
   "source": [
    "## Plotting the Accuracy and Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "6xE-nWNFyO7O",
    "outputId": "ba75344b-175e-49ca-bc83-88bb50b85f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4db1a2a310>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper left')\n",
    "\n",
    "#loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgZBWVIQyO7P"
   },
   "source": [
    "## Testing the Model on Sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcibAnlKyO7P",
    "outputId": "ebf60bca-a61d-4284-ccaf-b0b8769fd24e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49586385],\n",
       "       [0.49586385]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_1 = \"The movie was fantastic! I like it!\"\n",
    "test_sample_2 = \"Not a great movie, it was really bad...\"\n",
    "\n",
    "test_samples = [test_sample_1, test_sample_2]\n",
    "test_samples_tokens = tokenizer_obj.texts_to_sequences(test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen = 100)\n",
    "\n",
    "model.predict(x=test_samples_tokens_pad)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Text Classification Using Word2Vec and LSTMs on Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
